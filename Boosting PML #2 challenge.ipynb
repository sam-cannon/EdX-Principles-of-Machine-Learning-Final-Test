{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "#from statsmodels.api import datasets\n",
    "from sklearn import datasets ## Get dataset from sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sklm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sam Cannon\\\\Desktop\\\\Python\\\\Data Sets'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Sam Cannon\\\\Desktop\\\\Python\\\\Data Sets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('AdvWorksCusts.csv')\n",
    "labels = pd.read_csv('AW_BikeBuyer.csv')\n",
    "test = pd.read_csv('AW_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "Title                   16431\n",
       "FirstName                   0\n",
       "MiddleName               6985\n",
       "LastName                    0\n",
       "Suffix                  16517\n",
       "AddressLine1                0\n",
       "AddressLine2            16243\n",
       "City                        0\n",
       "StateProvinceName           0\n",
       "CountryRegionName           0\n",
       "PostalCode                  0\n",
       "PhoneNumber                 0\n",
       "BirthDate                   0\n",
       "Education                   0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "MaritalStatus               0\n",
       "HomeOwnerFlag               0\n",
       "NumberCarsOwned             0\n",
       "NumberChildrenAtHome        0\n",
       "TotalChildren               0\n",
       "YearlyIncome                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look for missing values\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just drop all of these columns\n",
    "train.drop('Title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('MiddleName', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Suffix', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('AddressLine2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID              0\n",
       "FirstName               0\n",
       "LastName                0\n",
       "AddressLine1            0\n",
       "City                    0\n",
       "StateProvinceName       0\n",
       "CountryRegionName       0\n",
       "PostalCode              0\n",
       "PhoneNumber             0\n",
       "BirthDate               0\n",
       "Education               0\n",
       "Occupation              0\n",
       "Gender                  0\n",
       "MaritalStatus           0\n",
       "HomeOwnerFlag           0\n",
       "NumberCarsOwned         0\n",
       "NumberChildrenAtHome    0\n",
       "TotalChildren           0\n",
       "YearlyIncome            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see if these are gone\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cool, so our data is \"clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode for gender and marital status to reduce amount of dummy variable columns, these can simply be recoded into binaries\n",
    "train['gender_recoded'] = train.Gender.map({'M':1, 'F':0})\n",
    "train['maritalstatus_recoded'] = train.MaritalStatus.map({'M':1, 'S':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy code for education, occupation and country\n",
    "train_dummies = pd.get_dummies(train, columns=[ 'Education', 'Occupation', 'CountryRegionName'], \n",
    "                                        prefix=['education', 'occupation', 'country'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CustomerID', 'FirstName', 'LastName', 'AddressLine1', 'City',\n",
       "       'StateProvinceName', 'PostalCode', 'PhoneNumber', 'BirthDate', 'Gender',\n",
       "       'MaritalStatus', 'HomeOwnerFlag', 'NumberCarsOwned',\n",
       "       'NumberChildrenAtHome', 'TotalChildren', 'YearlyIncome',\n",
       "       'gender_recoded', 'maritalstatus_recoded', 'education_Graduate Degree',\n",
       "       'education_High School', 'education_Partial College',\n",
       "       'education_Partial High School', 'occupation_Management',\n",
       "       'occupation_Manual', 'occupation_Professional',\n",
       "       'occupation_Skilled Manual', 'country_Canada', 'country_France',\n",
       "       'country_Germany', 'country_United Kingdom', 'country_United States'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look to see if our dummy columns made it\n",
    "train_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16519"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.CustomerID.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our features (transform into an array)\n",
    "features = np.array(train_dummies[[\n",
    "        'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome','TotalChildren'\n",
    "       ,'YearlyIncome', 'gender_recoded', 'maritalstatus_recoded'\n",
    "       ,'education_Graduate Degree', 'education_High School', 'education_Partial College', 'education_Partial High School'\n",
    "       ,'occupation_Management', 'occupation_Manual', 'occupation_Professional','occupation_Skilled Manual'\n",
    "       ,'country_Canada','country_France', 'country_Germany', 'country_United Kingdom'\n",
    "       ,'country_United States']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define labels (transform into an array)\n",
    "labels = np.array(labels.BikeBuyer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16519,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels are the same shape as our features, good\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam Cannon\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Sam Cannon\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.69564375, -1.31790504, -0.65479049, ..., -0.32612253,\n",
       "        -0.34036314, -0.85605071],\n",
       "       [-1.4375174 , -0.43988635,  1.32540431, ..., -0.32612253,\n",
       "        -0.34036314, -0.85605071],\n",
       "       [ 0.69564375, -0.43988635,  1.32540431, ..., -0.32612253,\n",
       "        -0.34036314, -0.85605071],\n",
       "       ...,\n",
       "       [ 0.69564375,  0.43813233, -0.65479049, ..., -0.32612253,\n",
       "        -0.34036314, -0.85605071],\n",
       "       [ 0.69564375,  0.43813233, -0.65479049, ..., -0.32612253,\n",
       "        -0.34036314, -0.85605071],\n",
       "       [ 0.69564375,  0.43813233, -0.65479049, ..., -0.32612253,\n",
       "        -0.34036314,  1.16815509]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale our features\n",
    "scale = preprocessing.StandardScaler()\n",
    "scale.fit(features)\n",
    "features = scale.transform(features)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are ready to begin creating our boosted decision tree Adaboost, we need to define the cross validation first, \n",
    "#inside and outside folds for best hyperparameters and model selection\n",
    "nr.seed(123)\n",
    "inside = ms.KFold(n_splits=10, shuffle = True)\n",
    "nr.seed(321)\n",
    "outside = ms.KFold(n_splits=10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "## Define the dictionary for the grid search and the model object to search on\n",
    "param_grid = {\"learning_rate\": [0.1, 1, 10]}\n",
    "## Define the AdaBoosted tree model\n",
    "nr.seed(3456)\n",
    "ab_clf = AdaBoostClassifier()  \n",
    "\n",
    "## Perform the grid search over the parameters\n",
    "nr.seed(4455)\n",
    "ab_clf = ms.GridSearchCV(estimator = ab_clf, param_grid = param_grid, \n",
    "                      cv = inside, # Use the inside folds\n",
    "                      scoring = 'roc_auc',\n",
    "                      return_train_score = True)\n",
    "ab_clf.fit(features, labels)\n",
    "print(ab_clf.best_estimator_.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean performance metric = 0.835\n",
      "SDT of the metric       = 0.006\n",
      "Outcomes by cv fold\n",
      "Fold  1    0.827\n",
      "Fold  2    0.842\n",
      "Fold  3    0.835\n",
      "Fold  4    0.838\n",
      "Fold  5    0.834\n",
      "Fold  6    0.833\n",
      "Fold  7    0.840\n",
      "Fold  8    0.834\n",
      "Fold  9    0.824\n",
      "Fold 10    0.842\n"
     ]
    }
   ],
   "source": [
    "#running the outer cross validation of the model\n",
    "nr.seed(498)\n",
    "cv_estimate = ms.cross_val_score(ab_clf, features, labels, \n",
    "                                 cv = outside) # Use the outside folds\n",
    "\n",
    "print('Mean performance metric = %4.3f' % np.mean(cv_estimate))\n",
    "print('SDT of the metric       = %4.3f' % np.std(cv_estimate))\n",
    "print('Outcomes by cv fold')\n",
    "for i, x in enumerate(cv_estimate):\n",
    "    print('Fold %2d    %4.3f' % (i+1, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results look really promising for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data, this is so we can test the model\n",
    "nr.seed(1115)\n",
    "indx = range(features.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = .3)\n",
    "X_train = features[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "X_test = features[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
       "          n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the boosting model using the optimal hyperparameters\n",
    "nr.seed(1115)\n",
    "ab_mod = AdaBoostClassifier(learning_rate = ab_clf.best_estimator_.learning_rate) \n",
    "ab_mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can see the hyperparameters match the optimal ones found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive      2927               399\n",
      "Actual negative       678               952\n",
      "\n",
      "Accuracy        0.78\n",
      "AUC             0.83\n",
      "Macro precision 0.76\n",
      "Macro recall    0.73\n",
      " \n",
      "           Positive      Negative\n",
      "Num case     3326          1630\n",
      "Precision    0.81          0.70\n",
      "Recall       0.88          0.58\n",
      "F1           0.84          0.64\n"
     ]
    }
   ],
   "source": [
    "#lets get a confusion matrix for the model and score it now\n",
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "\n",
    "def print_metrics(labels, probs, threshold):\n",
    "    scores = score_model(probs, threshold)\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy        %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print('AUC             %0.2f' % sklm.roc_auc_score(labels, probs[:,1]))\n",
    "    print('Macro precision %0.2f' % float((float(metrics[0][0]) + float(metrics[0][1]))/2.0))\n",
    "    print('Macro recall    %0.2f' % float((float(metrics[1][0]) + float(metrics[1][1]))/2.0))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "    \n",
    "probabilities = ab_mod.predict_proba(X_test)\n",
    "print_metrics(y_test, probabilities, 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets import the test set and clean, dummify, and scale it so we can predict new values\n",
    "test.drop('Title', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('MiddleName', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('Suffix', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop('AddressLine2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode for gender and marital status\n",
    "test['gender_recoded'] = test.Gender.map({'M':1, 'F':0})\n",
    "test['maritalstatus_recoded'] = test.MaritalStatus.map({'M':1, 'S':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy code for education, occupation and country\n",
    "test_dummies = pd.get_dummies(test, columns=[ 'Education', 'Occupation', 'CountryRegionName'], \n",
    "                                        prefix=['education', 'occupation', 'country'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our features\n",
    "features2 = np.array(test_dummies[[\n",
    "        'HomeOwnerFlag', 'NumberCarsOwned', 'NumberChildrenAtHome','TotalChildren'\n",
    "       ,'YearlyIncome', 'gender_recoded', 'maritalstatus_recoded'\n",
    "       ,'education_Graduate Degree', 'education_High School', 'education_Partial College', 'education_Partial High School'\n",
    "       ,'occupation_Management', 'occupation_Manual', 'occupation_Professional','occupation_Skilled Manual'\n",
    "       ,'country_Canada','country_France', 'country_Germany', 'country_United Kingdom'\n",
    "       ,'country_United States']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam Cannon\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Sam Cannon\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.41209489,  0.35928859, -0.72107754, ..., -0.32961713,\n",
       "        -0.31063037,  1.1055416 ],\n",
       "       [ 0.70816771,  0.35928859,  0.53297036, ..., -0.32961713,\n",
       "        -0.31063037, -0.90453403],\n",
       "       [ 0.70816771,  0.35928859, -0.72107754, ..., -0.32961713,\n",
       "        -0.31063037,  1.1055416 ],\n",
       "       ...,\n",
       "       [-1.41209489,  2.12050718,  1.15999431, ..., -0.32961713,\n",
       "        -0.31063037,  1.1055416 ],\n",
       "       [ 0.70816771, -0.5213207 , -0.72107754, ..., -0.32961713,\n",
       "        -0.31063037,  1.1055416 ],\n",
       "       [-1.41209489,  0.35928859, -0.72107754, ..., -0.32961713,\n",
       "        -0.31063037, -0.90453403]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scale our features\n",
    "scale = preprocessing.StandardScaler()\n",
    "scale.fit(features2)\n",
    "features2 = scale.transform(features2)\n",
    "features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictions = ab_mod.predict(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sweet! write this to a csv and lets go\n",
    "boosted_predictionsdf = pd.DataFrame(data=boosted_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictionsdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictionsdf.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = pd.DataFrame(data=test['CustomerID'])\n",
    "cid.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictions_with_cid = pd.merge(cid, boosted_predictionsdf, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictions_with_cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosted_predictions_with_cid.to_csv('boosted_predictions_with_cid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
